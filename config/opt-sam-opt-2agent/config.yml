batch_size: 32
checkpoint_dir: checkpoints/one_agent
checkpoint_freq: 3000
checkpoint_path: checkpoints/one_agent/checkpoint_00036000.pth.tar
checkpoints_dir: checkpoints
collision_penalty: 10
discount_factor: 0.99
experiment_name: large_columns
exploration_reward: 1
exploration_timesteps: 3000
final_exploration: 0.1
fixed_step_size: null
grad_norm_clipping: 10
inactivity_cutoff: 100
learning_rate: 0.01
learning_starts: 1000
log_dir: logs/one_agent
logs_dir: logs
ministep_size: 0.25
model_path: checkpoints/one_agent/model_00036000.pth.tar
nonmovement_penalty: 10
num_cubes: 1
num_input_channels: 4
obstacle_config: large_columns
partial_rewards_scale: 2.0
policy_type: dense_action_space
position_channel_scale: 0.25
random_seed: null
replay_buffer_size: 6000
room_length: 3.0
room_width: 3.0
run_name: 2agent
shortest_path_channel_scale: 0.25
steering_commands_num_turns: 4
target_update_freq: 1000
total_timesteps: 35000
use_double_dqn: true
use_opt_rule: 2
use_position_channel: false
use_shortest_path_channel: true
use_shortest_path_movement: true
use_shortest_path_partial_rewards: true
use_steering_commands: false
use_visit_frequency_channel: true
weight_decay: 0.0001

num_agents: 2
