batch_size: 32
checkpoint_dir: null
checkpoint_freq: 3000
checkpoint_path: null
checkpoints_dir: checkpoints
collision_penalty: 10
exploration_reward: 1
discount_factor: 0.99
experiment_name: large_columns
exploration_timesteps: 4000
final_exploration: 0.1
fixed_step_size: null
grad_norm_clipping: 10
inactivity_cutoff: 100
learning_rate: 0.01
learning_starts: 1000
log_dir: null
logs_dir: logs
ministep_size: 0.25
model_path: null
nonmovement_penalty: 10
num_cubes: 1
num_input_channels: 3
obstacle_config: large_columns
policy_type: dense_action_space
partial_rewards_scale: 2.0
position_channel_scale: 0.25
random_seed: null
replay_buffer_size: 6000
room_length: 3.0
room_width: 3.0
run_name:
shortest_path_channel_scale: 0.25
steering_commands_num_turns: 4
target_update_freq: 1000
total_timesteps: 25000
use_double_dqn: true
use_position_channel: false
use_visit_frequency_channel: false
use_shortest_path_channel: true
use_shortest_path_movement: true
use_shortest_path_partial_rewards: true
use_steering_commands: false
use_opt_rule: 0
weight_decay: 0.0001
